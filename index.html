<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Orion Voice Labs V3.1</title>
    
    <!-- React & ReactDOM -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    
    <!-- Babel for JSX -->
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- Google Generative AI SDK -->
    <script type="importmap">
      {
        "imports": {
          "@google/generative-ai": "https://esm.run/@google/generative-ai"
        }
      }
    </script>

    <style>
        body { background-color: #0f0f0f; color: #00ff41; font-family: 'Courier New', monospace; overflow: hidden; }
        @keyframes pulse { from { transform: scale(1); } to { transform: scale(1.1); } }
        .orb-pulse { animation: pulse 1s infinite alternate; }
        
        /* Custom Scrollbar */
        ::-webkit-scrollbar { width: 8px; }
        ::-webkit-scrollbar-track { background: #000; }
        ::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }
        ::-webkit-scrollbar-thumb:hover { background: #555; }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel" data-type="module">
        import { GoogleGenerativeAI } from "@google/generative-ai";
        const { useState, useEffect, useRef } = React;

        // --- HELPER: PCM to WAV Converter ---
        const pcmToWav = (base64PCM, sampleRate = 24000) => {
            const binaryString = window.atob(base64PCM);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const wavHeader = new ArrayBuffer(44);
            const view = new DataView(wavHeader);
            view.setUint32(0, 1179011410, false); // "RIFF"
            view.setUint32(4, 36 + len, true);    // File size
            view.setUint32(8, 1163280727, false); // "WAVE"
            view.setUint32(12, 544501094, false); // "fmt "
            view.setUint32(16, 16, true);         // Subchunk1Size
            view.setUint16(20, 1, true);          // AudioFormat
            view.setUint16(22, 1, true);          // NumChannels
            view.setUint32(24, sampleRate, true); // SampleRate
            view.setUint32(28, sampleRate * 2, true); // ByteRate
            view.setUint16(32, 2, true);          // BlockAlign
            view.setUint16(34, 16, true);         // BitsPerSample
            view.setUint32(36, 1635017060, false); // "data"
            view.setUint32(40, len, true);         // Subchunk2Size
            const blob = new Blob([view, bytes], { type: 'audio/wav' });
            return URL.createObjectURL(blob);
        };

        function App() {
            // State
            const [apiKey, setApiKey] = useState(localStorage.getItem("GEMINI_TEST_KEY") || "");
            const [selectedModel, setSelectedModel] = useState("gemini-1.5-flash"); // Default safe model
            const [showSettings, setShowSettings] = useState(false);
            const [status, setStatus] = useState("IDLE"); // IDLE, LISTENING, THINKING, SPEAKING
            const [logs, setLogs] = useState([]);
            
            // Refs
            const recognitionRef = useRef(null);
            const audioRef = useRef(new Audio());
            const debounceTimer = useRef(null); // Prevents rapid firing

            // Logger
            const addLog = (type, message) => {
                const timestamp = new Date().toLocaleTimeString().split(' ')[0];
                setLogs(prev => [{ time: timestamp, type, msg: message }, ...prev]);
            };

            // Initialize Speech Recognition
            useEffect(() => {
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    recognitionRef.current = new SpeechRecognition();
                    recognitionRef.current.continuous = false; // We want single commands
                    recognitionRef.current.interimResults = false;
                    recognitionRef.current.lang = 'en-US';

                    recognitionRef.current.onstart = () => {
                        setStatus("LISTENING");
                        addLog('INFO', 'Mic Active. Waiting for speech...');
                    };

                    recognitionRef.current.onresult = (event) => {
                        const transcript = event.results[0][0].transcript;
                        
                        // --- CRAZY MIC FIX ---
                        // 1. Ignore very short utterances (noise)
                        if (transcript.length < 5) {
                            addLog('IGNORED', `Noise detected: "${transcript}"`);
                            return;
                        }

                        // 2. Clear any previous timers
                        if (debounceTimer.current) clearTimeout(debounceTimer.current);

                        // 3. Wait 500ms to ensure user stopped talking, then fire
                        debounceTimer.current = setTimeout(() => {
                            if (status !== 'THINKING') { // Don't interrupt if already thinking
                                addLog('USER üó£Ô∏è', transcript);
                                handleBrainProcess(transcript);
                            }
                        }, 500);
                    };

                    recognitionRef.current.onerror = (event) => {
                        if (event.error === 'no-speech') return; // Ignore silence errors
                        setStatus("IDLE");
                        addLog('ERROR', 'Speech Error: ' + event.error);
                    };

                    recognitionRef.current.onend = () => {
                        // Only go idle if we aren't processing
                        if(status === "LISTENING") setStatus("IDLE");
                    };
                } else {
                    addLog('ERROR', 'Browser does not support Speech Recognition.');
                }
            }, [apiKey, status, selectedModel]);

            // --- 1. THE BRAIN ---
            const handleBrainProcess = async (userText) => {
                if (!apiKey) return alert("Please set API Key in settings!");
                
                // Stop listening immediately to prevent self-hearing
                recognitionRef.current.stop();
                setStatus("THINKING");
                
                try {
                    const genAI = new GoogleGenerativeAI(apiKey);
                    const model = genAI.getGenerativeModel({ model: selectedModel }); 
                    
                    addLog('SYSTEM', `Sending to ${selectedModel}...`);
                    
                    const result = await model.generateContent(`
                        You are Orion, a highly advanced, witty AI interface.
                        Be concise. Reply in 1-2 sentences maximum.
                        User said: "${userText}"
                    `);
                    
                    const responseText = result.response.text();
                    addLog('GEMINI üß†', responseText);
                    
                    handleVoiceSynthesis(responseText);

                } catch (error) {
                    addLog('ERROR', 'Brain Error: ' + error.message);
                    setStatus("IDLE");
                }
            };

            // --- 2. THE VOICE ---
            const handleVoiceSynthesis = async (textToSpeak) => {
                addLog('SYSTEM', 'Synthesizing Audio...');
                
                try {
                    // Using the new TTS endpoint
                    const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
                    
                    const payload = {
                        contents: [{ parts: [{ text: textToSpeak }] }],
                        generationConfig: {
                            responseModalities: ["AUDIO"],
                            speechConfig: {
                                voiceConfig: {
                                    prebuiltVoiceConfig: { voiceName: "Kore" }
                                }
                            }
                        }
                    };

                    const response = await fetch(url, {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify(payload)
                    });

                    const data = await response.json();
                    if (data.error) throw new Error(data.error.message);

                    const audioData = data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
                    if (!audioData) throw new Error("No audio data.");

                    addLog('SYSTEM', 'Playing Audio...');
                    
                    const wavUrl = pcmToWav(audioData, 24000);
                    audioRef.current.src = wavUrl;
                    
                    audioRef.current.onplay = () => setStatus("SPEAKING");
                    audioRef.current.onended = () => {
                        setStatus("IDLE");
                        addLog('INFO', 'Done. Ready.');
                    };

                    await audioRef.current.play();

                } catch (error) {
                    addLog('ERROR', 'Voice Synth Failed: ' + error.message);
                    setStatus("IDLE");
                }
            };

            const toggleListening = () => {
                if (status === "LISTENING") recognitionRef.current.stop();
                else recognitionRef.current.start();
            };

            const saveKey = (val) => {
                setApiKey(val);
                localStorage.setItem("GEMINI_TEST_KEY", val);
            };

            // --- VISUALS ---
            const getOrbColor = () => {
                switch(status) {
                    case "LISTENING": return "#ff4444"; // Red
                    case "SPEAKING": return "#00ff41"; // Green
                    case "THINKING": return "#00aaff"; // Blue
                    default: return "#333"; // Gray
                }
            };

            const getOrbIcon = () => {
                switch(status) {
                    case "LISTENING": return "üé§";
                    case "SPEAKING": return "üîä";
                    case "THINKING": return "üß†";
                    default: return "üõë";
                }
            };

            return (
                <div className="flex flex-col h-screen">
                    {/* Header */}
                    <div className="p-5 flex justify-between border-b border-gray-800 bg-gray-900">
                        <div>
                            <h1 className="text-xl font-bold">ü¶Å ORION VOICE LABS</h1>
                            <div className="text-xs text-gray-500">Model: {selectedModel}</div>
                        </div>
                        <button onClick={() => setShowSettings(!showSettings)} className="text-2xl hover:text-white transition">‚öôÔ∏è</button>
                    </div>

                    {/* Main Area */}
                    <div className="flex-1 flex flex-col items-center justify-center relative">
                        
                        <div 
                            onClick={toggleListening}
                            className={`w-40 h-40 rounded-full flex items-center justify-center cursor-pointer transition-all duration-300 ${status !== 'IDLE' ? 'orb-pulse' : ''}`}
                            style={{ 
                                backgroundColor: getOrbColor(),
                                boxShadow: status !== 'IDLE' ? `0 0 50px ${getOrbColor()}` : 'none'
                            }}
                        >
                            <span className="text-5xl filter drop-shadow-lg">{getOrbIcon()}</span>
                        </div>

                        <p className="mt-8 text-gray-500 font-bold tracking-widest animate-pulse">
                            {status === "IDLE" ? "TAP TO SPEAK" : status}
                        </p>

                        {/* Settings Modal */}
                        {showSettings && (
                            <div className="absolute top-5 bg-gray-900 p-6 border border-gray-700 rounded-lg shadow-2xl z-50 w-80">
                                <h3 className="mb-4 text-white font-bold border-b border-gray-700 pb-2">Configuration</h3>
                                
                                <label className="text-gray-400 text-xs uppercase">Gemini API Key</label>
                                <input 
                                    type="text" 
                                    value={apiKey} 
                                    onChange={(e) => saveKey(e.target.value)}
                                    placeholder="AIza..."
                                    className="mb-4 p-2 w-full bg-black border border-gray-600 rounded text-green-400 focus:outline-none focus:border-green-500"
                                />

                                <label className="text-gray-400 text-xs uppercase">Brain Model</label>
                                <select 
                                    value={selectedModel}
                                    onChange={(e) => setSelectedModel(e.target.value)}
                                    className="p-2 w-full bg-black border border-gray-600 rounded text-white focus:outline-none focus:border-green-500"
                                >
                                    <option value="gemini-2.0-flash-exp">Gemini 2.0 Flash (Exp)</option>
                                    <option value="gemini-1.5-flash">Gemini 1.5 Flash (Standard)</option>
                                    <option value="gemini-1.5-pro">Gemini 1.5 Pro (Smarter)</option>
                                    <option value="gemini-3.0-flash">Gemini 3.0 Flash (If avail)</option>
                                </select>

                                <div className="mt-6 flex justify-end">
                                    <button onClick={() => setShowSettings(false)} className="bg-green-600 hover:bg-green-700 text-white px-4 py-2 rounded">Done</button>
                                </div>
                            </div>
                        )}
                    </div>

                    {/* Debug Console */}
                    <div className="h-48 bg-black border-t-2 border-gray-800 p-4 overflow-y-auto font-mono text-sm">
                        <div className="text-gray-600 mb-2">--- ORION DEBUG STREAM ---</div>
                        {logs.map((log, i) => (
                            <div key={i} className="mb-1 border-b border-gray-900 pb-1">
                                <span className="text-gray-600 text-xs">[{log.time}]</span>
                                <span className={`font-bold mx-2 ${
                                    log.type === 'ERROR' ? 'text-red-500' : 
                                    log.type === 'USER üó£Ô∏è' ? 'text-yellow-400' : 
                                    log.type === 'GEMINI üß†' ? 'text-cyan-400' : 'text-green-500'
                                }`}>{log.type}:</span>
                                <span className="text-gray-300">{log.msg}</span>
                            </div>
                        ))}
                    </div>
                </div>
            );
        }

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>
